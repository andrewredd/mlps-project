{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPS - Mercari Price ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/train.tsv\", delimiter=\"\\t\", index_col=0)\n",
    "\n",
    "# remove items with out a price\n",
    "data = data[pd.notna(data[\"price\"])]\n",
    "\n",
    "data[\"item_description\"] = data[\"item_description\"].replace(\"No description yet\", \"\")\n",
    "data[\"item_description\"] = data[\"item_description\"].replace(np.nan, \"\")\n",
    "\n",
    "temp = data[\"category_name\"].fillna('').str.split('/')\n",
    "              \n",
    "data[\"category_name_1\"] = temp.str[0]\n",
    "data[\"category_name_2\"] = temp.str[1]\n",
    "data[\"category_name_3\"] = temp.str[2:].str.join(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement porter stemming in count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "\n",
    "class StemmerTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.ps = PorterStemmer()\n",
    "        self.translator = str.maketrans('', '', string.punctuation + string.digits)\n",
    "    def __call__(self, doc):\n",
    "        return [self.ps.stem(w) for w in doc\n",
    "                .encode('ascii', errors='ignore')\n",
    "                .decode('ascii')\n",
    "                .translate(self.translator)\n",
    "                .split()]\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase = True,\n",
    "                             max_df = .5,\n",
    "                             min_df = .001,\n",
    "                             tokenizer = StemmerTokenizer(),\n",
    "                             stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tfm = vectorizer.fit_transform(data[\"item_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_ \n",
    "removed_words = vectorizer.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tfidf_vectorizer = TfidfTransformer()\n",
    "tfidf_transformed = tfidf_vectorizer.fit_transform(tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results for time savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "save_npz(\"tfm.npz\", tfm)\n",
    "save_npz(\"tfidf_transformed.npz\", tfidf_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab: write vectorized words to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "with open(\"vocabulary.txt\", \"w\") as f:\n",
    "    f.write(\"\".join([k + '\\n' for k, v in sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><hr><hr>\n",
    "\n",
    "# Load files as necessary for time savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "tfm = load_npz(\"Data/tfm.npz\")\n",
    "tfidf_transformed = load_npz(\"Data/tfidf_transformed.npz\")\n",
    "categorical = pd.read_csv('Data/train_clean.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-filtering  1482535\n",
      "post-filtering  1478823\n"
     ]
    }
   ],
   "source": [
    "# take the log of price (0.000000001 added for item with 0 as price)\n",
    "categorical['log(price)'] = np.log(categorical['price'] + 0.000000001)\n",
    "\n",
    "# calculate 6 st dev of log(price)\n",
    "st_dev_log_price_6 = categorical['log(price)'].std()*6\n",
    "\n",
    "print(\"pre-filtering \",len(categorical))\n",
    "\n",
    "# find points that are not outliers\n",
    "not_outliers = np.array((categorical['log(price)'] < st_dev_log_price_6) & (categorical['log(price)'] > (- st_dev_log_price_6)))\n",
    "\n",
    "# filter datasets to data only around 6 st dev of log(price)\n",
    "cleaned_categorical = categorical[not_outliers]\n",
    "cleaned_categorical.reset_index(drop = True, inplace = True)\n",
    "tfm = tfm[not_outliers]\n",
    "tfidf_transformed = tfidf_transformed[not_outliers]\n",
    "\n",
    "print(\"post-filtering \",len(cleaned_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>log(price)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1478823.000</td>\n",
       "      <td>1478823.000</td>\n",
       "      <td>1478823.000</td>\n",
       "      <td>1478823.000</td>\n",
       "      <td>1478823.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>741229.160</td>\n",
       "      <td>1.907</td>\n",
       "      <td>25.753</td>\n",
       "      <td>0.447</td>\n",
       "      <td>2.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>427967.781</td>\n",
       "      <td>0.903</td>\n",
       "      <td>29.028</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>370559.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>741224.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1111850.500</td>\n",
       "      <td>3.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1482534.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>347.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5.849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id  item_condition_id       price    shipping  log(price)\n",
       "count 1478823.000        1478823.000 1478823.000 1478823.000 1478823.000\n",
       "mean   741229.160              1.907      25.753       0.447       2.907\n",
       "std    427967.781              0.903      29.028       0.497       0.776\n",
       "min         0.000              1.000       3.000       0.000       1.099\n",
       "25%    370559.500              1.000      10.000       0.000       2.303\n",
       "50%    741224.000              2.000      17.000       0.000       2.833\n",
       "75%   1111850.500              3.000      29.000       1.000       3.367\n",
       "max   1482534.000              5.000     347.000       1.000       5.849"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_categorical.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:5984: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2862: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleaned_categorical[\"brand_name\"][cleaned_categorical[\"brand_name\"].isnull()] = \"No Brand Info\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x130b87ef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130891ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "cleaned_categorical['log(price)'].plot.hist(bins= 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478823, 1793)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478823, 1793)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478823, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_categorical.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_categorical = cleaned_categorical['price']\n",
    "cleaned_categorical.drop([\"train_id\",\"name\",\"category_name\",\"item_description\",\"price\", 'log(price)'], axis=1, inplace=True)\n",
    "cleaned_categorical[\"item_condition_id\"] = cleaned_categorical[\"item_condition_id\"].astype('str', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_categorical.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cleaned_categorical = pd.get_dummies(cleaned_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test Train sample size\n",
    "import numpy as np\n",
    "n_sample = 100000\n",
    "sample = np.random.permutation(y_categorical.shape[0])[:n_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_categorical_sample = y_categorical[sample]\n",
    "ohe_cleaned_categorical_sample = ohe_cleaned_categorical.iloc[sample]\n",
    "tfidf_transformed_sample = tfidf_transformed[sample]\n",
    "\n",
    "ohe_cleaned_categorical_sample.reset_index(drop = True, inplace = True);\n",
    "y_categorical_sample.reset_index(drop = True, inplace = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_categorical.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "yTrain, yTest, XTrain, XTest, tfidfTrain, tfidfTest = train_test_split(\n",
    "    y_categorical_sample, ohe_cleaned_categorical_sample, tfidf_transformed_sample, test_size=0.3, random_state=95)\n",
    "\n",
    "yTrain.reset_index(drop = True, inplace = True)\n",
    "yTest.reset_index(drop = True, inplace = True)\n",
    "XTrain.reset_index(drop = True, inplace = True)\n",
    "XTest.reset_index(drop = True, inplace = True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# specify number of folds\n",
    "from sklearn.model_selection import KFold\n",
    "folds = 2\n",
    "kf = KFold(n_splits=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n",
      "0\n",
      "0 0.001\n",
      "0 0.001 0.001\n",
      "0 0.001 0.01\n",
      "0 0.01\n",
      "0 0.01 0.001\n",
      "0 0.01 0.01\n",
      "0 0.1\n",
      "0 0.1 0.001\n",
      "0 0.1 0.01\n",
      "0 1\n",
      "0 1 0.001\n",
      "0 1 0.01\n",
      "1\n",
      "1 0.001\n",
      "1 0.001 0.001\n",
      "1 0.001 0.01\n",
      "1 0.01\n",
      "1 0.01 0.001\n",
      "1 0.01 0.01\n",
      "1 0.1\n",
      "1 0.1 0.001\n",
      "1 0.1 0.01\n",
      "1 1\n",
      "1 1 0.001\n",
      "1 1 0.01\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Test train and validate\n",
    "alpha_values = [0.001, 0.01, 0.1, 1]\n",
    "alpha_inner_values = [0.001, 0.01]\n",
    "from sklearn.linear_model import Lasso\n",
    "import copy\n",
    "\n",
    "mseOuterTrain = []\n",
    "mseOuterVal = []\n",
    "mseInnerTrain = []\n",
    "mseInnerVal = []\n",
    "mseOverallTrain = []\n",
    "mseOverallVal= []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(yTrain)):\n",
    "    print(i)\n",
    "    yTrain_fold = yTrain.iloc[train_index]\n",
    "    yVal_fold = yTrain.iloc[val_index]\n",
    "\n",
    "    XTrain_fold = XTrain.iloc[train_index]\n",
    "    XVal_fold = XTrain.iloc[val_index]\n",
    "    \n",
    "    tfidfTrain_fold = tfidfTrain[train_index]\n",
    "    tfidfVal_fold = tfidfTrain[val_index]\n",
    "    \n",
    "\n",
    "    for a_outer in alpha_values:\n",
    "        print(i, a_outer)\n",
    "        lasso = Lasso(alpha=a_outer, random_state=111, max_iter=1000).fit(XTrain_fold, yTrain_fold)\n",
    "        predict_train = lasso.predict(XTrain_fold)\n",
    "        train_residuals = yTrain_fold - predict_train\n",
    "        mseOuterTrain.append(copy.deepcopy((i, a_outer ,None, np.square(train_residuals).mean())))\n",
    "        \n",
    "        predict_val = lasso.predict(XVal_fold)\n",
    "        val_residuals = yVal_fold - predict_val\n",
    "        mseOuterVal.append(copy.deepcopy((i, a_outer , None, np.square(val_residuals).mean())))\n",
    "        \n",
    "        for a_inner in alpha_inner_values:\n",
    "            print(i, a_outer, a_inner)\n",
    "            lasso_inner = Lasso(alpha=a_inner, random_state=111, max_iter=1000).fit(tfidfTrain_fold, train_residuals)\n",
    "            predict_inner_train = lasso_inner.predict(tfidfTrain_fold)\n",
    "            inner_train_residuals = train_residuals - predict_inner_train\n",
    "            mseInnerTrain.append(copy.deepcopy((i, a_inner, np.square(inner_train_residuals).mean())))\n",
    "\n",
    "            predict_inner_val = lasso_inner.predict(tfidfVal_fold)\n",
    "            inner_val_residuals = val_residuals - predict_inner_val\n",
    "            mseInnerVal.append(copy.deepcopy((i, a_inner, np.square(inner_val_residuals).mean())))\n",
    "\n",
    "            residuals_overall_train = yTrain_fold - predict_train - predict_inner_train\n",
    "            mseOverallTrain.append(copy.deepcopy((i, a_outer, a_inner, np.square(residuals_overall_train).mean())))\n",
    "\n",
    "            residuals_overall_val = yVal_fold - predict_val - predict_inner_val\n",
    "            mseOverallVal.append(copy.deepcopy((i, a_outer, a_inner, np.square(residuals_overall_val).mean())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.001, 0.001, 537.8424368915587),\n",
       " (1, 0.01, 0.001, 541.7957137672096),\n",
       " (1, 0.001, 0.01, 548.5032824515748),\n",
       " (1, 0.01, 0.01, 555.2455748046898),\n",
       " (1, 0.1, 0.001, 593.1901232125064),\n",
       " (0, 0.001, 0.001, 593.6364120389524),\n",
       " (0, 0.01, 0.001, 598.3875588873835),\n",
       " (0, 0.001, 0.01, 603.9947970657068),\n",
       " (0, 0.01, 0.01, 611.1155584590944),\n",
       " (1, 0.1, 0.01, 617.188612694948),\n",
       " (1, 1, 0.001, 631.4570159583806),\n",
       " (0, 0.1, 0.001, 647.547198049096),\n",
       " (1, 1, 0.01, 658.8781379084553),\n",
       " (0, 0.1, 0.01, 671.8913832212985),\n",
       " (0, 1, 0.001, 691.6456001061263),\n",
       " (0, 1, 0.01, 723.3536005844179)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted(mseOverallVal, key = operator.itemgetter(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-8ce3192fb4a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmseOverallVal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fold1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fold2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MSE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.001, None, 569.5284216644386),\n",
       " (1, 0.01, None, 584.1053047616421),\n",
       " (0, 0.001, None, 624.6809628402181),\n",
       " (0, 0.01, None, 640.466910979057),\n",
       " (1, 0.1, None, 683.212800645272),\n",
       " (0, 0.1, None, 737.6382676182643),\n",
       " (1, 1, None, 779.749562256277),\n",
       " (0, 1, None, 840.4386399922018)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "sorted(mseOuterVal, key = operator.itemgetter(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.001</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.500</td>\n",
       "      <td>565.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.500</td>\n",
       "      <td>576.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.010</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.500</td>\n",
       "      <td>570.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.500</td>\n",
       "      <td>583.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.100</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.500</td>\n",
       "      <td>620.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.500</td>\n",
       "      <td>644.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.000</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.500</td>\n",
       "      <td>661.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.500</td>\n",
       "      <td>691.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       3\n",
       "1     2                  \n",
       "0.001 0.001 0.500 565.739\n",
       "      0.010 0.500 576.249\n",
       "0.010 0.001 0.500 570.092\n",
       "      0.010 0.500 583.181\n",
       "0.100 0.001 0.500 620.369\n",
       "      0.010 0.500 644.540\n",
       "1.000 0.001 0.500 661.551\n",
       "      0.010 0.500 691.116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mseOverallVal).groupby([1,2]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.500</td>\n",
       "      <td>597.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.500</td>\n",
       "      <td>612.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.500</td>\n",
       "      <td>710.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.500</td>\n",
       "      <td>810.094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       3\n",
       "1                  \n",
       "0.001 0.500 597.105\n",
       "0.010 0.500 612.286\n",
       "0.100 0.500 710.426\n",
       "1.000 0.500 810.094"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mseOuterVal).groupby([1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33348268747080134"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import copy\n",
    "lasso = Lasso(alpha=0.001, random_state=111, max_iter=1000).fit(XTrain, yTrain)\n",
    "pred = lasso.predict(XTrain)\n",
    "lasso.score(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "# import copy\n",
    "# lasso = Lasso(alpha=0.1, random_state=111, max_iter=1000).fit(XTrain, yTrain)\n",
    "# pred = lasso.predict(XTrain)\n",
    "# lasso.score(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0974643236016256"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_res = Lasso(alpha=0.001, random_state=111, max_iter=1000).fit(tfidfTrain, (pred - yTrain))\n",
    "pred_res = lasso_res.predict(tfidfTrain)\n",
    "lasso_res.score(tfidfTrain, (pred - yTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_res = lasso_res.predict(tfidfTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pred_plus = pred + pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692.055945829208\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzVFFoCiK0ub8/wfFENRRuXngAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x138e71e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = lasso.predict(XTrain)\n",
    "\n",
    "pred_res = lasso_res.predict(tfidfTrain)\n",
    "print(np.square(yTrain - pred - pred_res).mean())\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.scatter(yTrain, yTrain-pred, c= \"r\", label = \"Stage1\")\n",
    "plt.scatter(yTrain, yTrain-pred - pred_res, c = \"b\", label = \"Stage1 & Stage2\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Price\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.savefig(\"moneygraph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.square(yTrain-pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.square(yTrain-pred_plus).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-9.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-13.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>-6.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>-1.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>15.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>-1.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>-0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>-0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>-6.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>-5.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>-27.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>-6.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>-4.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>-20.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>-8.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>-0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>-0.272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>-5.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>8.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1793 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0     -0.000\n",
       "1      0.000\n",
       "2     -8.118\n",
       "3    -10.192\n",
       "4      0.000\n",
       "5      4.240\n",
       "6      0.000\n",
       "7     -0.000\n",
       "8     -5.199\n",
       "9      0.000\n",
       "10    -0.000\n",
       "11     0.000\n",
       "12     0.000\n",
       "13     6.269\n",
       "14     0.000\n",
       "15    -0.000\n",
       "16    14.395\n",
       "17     0.000\n",
       "18    -9.032\n",
       "19     0.000\n",
       "20    -0.000\n",
       "21     0.482\n",
       "22     2.410\n",
       "23     4.320\n",
       "24     0.000\n",
       "25     0.000\n",
       "26    -0.000\n",
       "27   -13.121\n",
       "28     0.000\n",
       "29     0.000\n",
       "...      ...\n",
       "1763  -6.700\n",
       "1764  -1.370\n",
       "1765  15.715\n",
       "1766  -0.000\n",
       "1767   0.000\n",
       "1768   1.814\n",
       "1769  -1.759\n",
       "1770   0.000\n",
       "1771  -0.192\n",
       "1772  -0.402\n",
       "1773  -6.648\n",
       "1774  -5.205\n",
       "1775   0.000\n",
       "1776 -27.931\n",
       "1777   0.000\n",
       "1778  -6.887\n",
       "1779  -4.093\n",
       "1780 -20.085\n",
       "1781   1.809\n",
       "1782  -0.000\n",
       "1783   0.000\n",
       "1784  -8.390\n",
       "1785  -0.578\n",
       "1786  -0.272\n",
       "1787   0.000\n",
       "1788  -0.000\n",
       "1789  -0.000\n",
       "1790  -5.768\n",
       "1791   8.967\n",
       "1792   0.000\n",
       "\n",
       "[1793 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "vocab = np.genfromtxt(\"Data/vocabulary.txt\",dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApMAAAHWCAYAAAArawK/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmQQAIDOTAABkFw3KBqmjgTNKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13d7dcf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def makeWC(vocab, data, save_name, height, width):\n",
    "    dictionary = dict(zip(vocab, data))\n",
    "    wc = WordCloud(background_color=\"white\", width=1100, height= 800)\n",
    "    wc.generate_from_frequencies(frequencies = dictionary)\n",
    "    plt.figure(figsize=(height,width))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imsave(save_name, wc, dpi=600)\n",
    "\n",
    "wc = makeWC(vocab[np.where(lasso_res.coef_ > 0)], lasso_res.coef_[np.where(lasso_res.coef_ > 0)], \"WC_lasso_coef_final_model.png\", 11,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   5,   13,   16,   21,   22,   23,   40,   44,   45,   57,   58,\n",
       "          59,   60,   63,   75,   78,   80,   89,   96,   99,  101,  102,\n",
       "         106,  117,  121,  122,  134,  136,  143,  147,  164,  166,  168,\n",
       "         172,  176,  182,  186,  188,  189,  193,  198,  203,  209,  210,\n",
       "         211,  214,  222,  230,  239,  245,  249,  251,  255,  257,  258,\n",
       "         259,  268,  271,  275,  277,  284,  285,  288,  290,  295,  306,\n",
       "         307,  310,  311,  313,  327,  332,  333,  335,  349,  354,  365,\n",
       "         368,  370,  375,  383,  398,  407,  415,  417,  420,  421,  423,\n",
       "         427,  432,  433,  436,  440,  442,  443,  452,  456,  471,  473,\n",
       "         474,  475,  481,  482,  492,  495,  507,  517,  519,  523,  528,\n",
       "         529,  540,  542,  555,  557,  562,  564,  565,  570,  572,  577,\n",
       "         579,  583,  585,  597,  600,  601,  607,  615,  616,  618,  626,\n",
       "         628,  629,  630,  638,  642,  648,  649,  650,  652,  667,  669,\n",
       "         671,  680,  681,  692,  698,  699,  709,  717,  720,  723,  733,\n",
       "         739,  751,  754,  758,  760,  774,  775,  777,  780,  789,  792,\n",
       "         793,  797,  798,  803,  804,  806,  807,  817,  819,  822,  824,\n",
       "         830,  833,  841,  843,  856,  858,  861,  864,  865,  873,  880,\n",
       "         884,  888,  893,  899,  915,  922,  923,  924,  926,  934,  935,\n",
       "         937,  939,  941,  943,  946,  951,  952,  953,  956,  958,  964,\n",
       "         967,  969,  978,  999, 1002, 1004, 1006, 1007, 1009, 1012, 1018,\n",
       "        1021, 1027, 1029, 1036, 1037, 1051, 1057, 1061, 1062, 1063, 1068,\n",
       "        1073, 1081, 1082, 1085, 1090, 1103, 1105, 1108, 1111, 1112, 1113,\n",
       "        1123, 1129, 1130, 1131, 1137, 1143, 1144, 1148, 1155, 1163, 1168,\n",
       "        1186, 1190, 1199, 1201, 1204, 1211, 1215, 1218, 1219, 1221, 1226,\n",
       "        1236, 1244, 1251, 1258, 1269, 1271, 1278, 1283, 1287, 1295, 1311,\n",
       "        1313, 1317, 1325, 1326, 1327, 1328, 1334, 1340, 1345, 1348, 1357,\n",
       "        1358, 1367, 1372, 1373, 1374, 1379, 1382, 1383, 1384, 1388, 1391,\n",
       "        1394, 1397, 1399, 1402, 1403, 1412, 1415, 1418, 1419, 1420, 1422,\n",
       "        1426, 1428, 1429, 1430, 1436, 1439, 1440, 1442, 1446, 1450, 1451,\n",
       "        1453, 1454, 1462, 1464, 1468, 1470, 1472, 1476, 1479, 1482, 1486,\n",
       "        1489, 1490, 1492, 1502, 1505, 1510, 1512, 1514, 1518, 1519, 1526,\n",
       "        1528, 1529, 1531, 1532, 1534, 1539, 1540, 1544, 1547, 1549, 1551,\n",
       "        1552, 1555, 1558, 1562, 1563, 1566, 1570, 1573, 1575, 1576, 1582,\n",
       "        1592, 1603, 1613, 1615, 1621, 1623, 1626, 1631, 1632, 1634, 1639,\n",
       "        1643, 1648, 1655, 1656, 1659, 1666, 1667, 1670, 1671, 1672, 1681,\n",
       "        1690, 1693, 1705, 1711, 1715, 1721, 1723, 1727, 1729, 1730, 1732,\n",
       "        1733, 1736, 1739, 1745, 1751, 1757, 1758, 1759, 1761, 1765, 1768,\n",
       "        1781, 1791]),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(lasso_res.coef_ > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso: Category (non-text) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = pd.read_csv('Data/vocabulary.txt', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "\n",
    "#alpha_values = np.logspace(-4, 2, 6)\n",
    "alpha_values = [0.001,0.01,0.1]\n",
    "\n",
    "mseRow = []\n",
    "mseAll = []\n",
    "mseOuterTrain = []\n",
    "mseOuterValidate = []\n",
    "mseInner = []\n",
    "\n",
    "#manually grid search over alpha\n",
    "for alphaOut in alpha_values:\n",
    "    \n",
    "    #non-Text data\n",
    "    lasso = Lasso(alpha=alphaOut, random_state=111, max_iter=1000).fit(XTrain, yTrain)\n",
    "    yPredOut = lasso.predict(XValid)\n",
    "    residuals = yValid - yPredOut\n",
    "    \n",
    "    mseRow = []\n",
    "    \n",
    "    #can't figure out how to implement a validation or test accuracy as the training of the inner model is dependent \n",
    "    # on the outermodel's predictions.  If we predict on XValid, then we need to train the inner model on XValid.\n",
    "    # not sure if this makes sense\n",
    "    \n",
    "    #GridSearch manually\n",
    "    for alphaIn in alpha_values:\n",
    "        lassoTF = Lasso(alpha=alphaIn, random_state=777, max_iter=1000).fit(tfidfValid, residuals)\n",
    "        yPredIn = lassoTF.predict(tfidfValid)\n",
    "        \n",
    "        #add predictions from non-Text and Text regressions\n",
    "        yPredFull = yPredOut + yPredIn\n",
    "        \n",
    "        #calc mse between full predictions & actuals\n",
    "        mseRow.append(mean_squared_error(yValid, yPredFull))\n",
    "    \n",
    "    #store for of mse's\n",
    "    mseAll.append(mseRow)\n",
    "    \n",
    "mseAll = np.array(mseAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get bestAlphaOut & In based on the smallest mse from gridsearch\n",
    "bestAlpha_idx = np.unravel_index(np.argmin(mseAll), mseAll.shape)\n",
    "#bestAlpha_idx[0]\n",
    "bestAlphaOut = alpha_values[bestAlpha_idx[0]]\n",
    "bestAlphaIn = alpha_values[bestAlpha_idx[1]]\n",
    "print()\n",
    "print(\"Best Alpha for Outer Lasso (non-text): {}\".format(bestAlphaOut))\n",
    "print(\"Best Alpha for Linner Lasso (text): {}\".format(bestAlphaIn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run final model with bestAlphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=bestAlphaOut, random_state=111).fit(XTrain, yTrain)\n",
    "yPredOut = lasso.predict(XValid)\n",
    "residualsBest = yValid - yPredOut\n",
    "\n",
    "lassoTF = Lasso(alpha=bestAlphaIn, random_state=111).fit(tfidfTrain, residualsBest)\n",
    "yPredIn = lasso.predict(tfidfValid)\n",
    "\n",
    "yPredFull = yPredOut + yPredIn\n",
    "\n",
    "mse_Final = mean_squared_error(yValid, yPredFull)\n",
    "print(\"The MSE for the final tuned models is: {}\".format(mse_Final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(lasso, 'lasso_cat.pkl')\n",
    "joblib.dump(lassTF, 'lasso_tfidf.pkl')\n",
    "#clf = joblib.load('lasso_cat.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine non-Text & text data and run Lasso to see if prediction is diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine non-Text and Text to test it out\n",
    "# tfDTrain = tfidfTrain.todense()\n",
    "# comboTrain = pd.concat([XTrain.reset_index(drop = True), pd.DataFrame(tfDTrain)], axis=1)\n",
    "# comboTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save lasso on category data as DataFrame, write to csv\n",
    "# lasso_cat_coef = pd.DataFrame(lasso.coef_, index=XTrain.columns)\n",
    "# lasso_cat_coef.to_csv(\"lasso_cat_coef.csv\")\n",
    "\n",
    "# residualsDF = pd.DataFrame(residuals)\n",
    "# residualsDF.to_csv(\"residuals.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso: Text data on residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save lasso on TFIDF data as DataFrame, write to csv\n",
    "# lasso_tfidf_coef = pd.DataFrame(lassoTF.coef_, index=vocab.iloc[:,0].values)\n",
    "# lasso_tfidf_coef.to_csv(\"lasso_tfidf_coef.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso: Text data on residuals (per category1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the category1 column headers\n",
    "cat1_cols = XTrain.iloc[:,4815:4825].columns\n",
    "\n",
    "#reset index so can filter using list of indices\n",
    "residuals.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cat1_coefs = []\n",
    "tfidfTrain_df = pd.DataFrame(tfidfTrain.todense())  #I think can remove this and uncomment tocsr() line below\n",
    "\n",
    "for cat1 in cat1_cols:\n",
    "    #get indices where this category=1\n",
    "    idx = np.where(XTrain[cat1] == 1)[0]\n",
    "   \n",
    "    #filter data with the indices\n",
    "    X_tf = tfidfTrain_df.iloc[idx,:]   #Don't think need to use this, uncomment next time to deal with sparse\n",
    "    #X_tf = tfidfTrain.tocsr()[idx,:]  #way to filter sparse matrx with row indices\n",
    "    y_tf = residuals[idx]\n",
    "    \n",
    "    #run Lasso, fit, store coef array\n",
    "    lassoCat = Lasso(alpha=bestAlphaIn, random_state=10)\n",
    "    lassoCat.fit(X_tf, y_tf)\n",
    "\n",
    "    #add this cat1 coefs to a list\n",
    "    cat1_coefs.append(lassoCat.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#covert to DF with cols=vocab and index=category1 names\n",
    "lasso_allCat1_coef = pd.DataFrame(cat1_coefs, columns=vocab.iloc[:,0].values, index=cat1_cols)\n",
    "lasso_allCat1_coef.to_csv(\"lass_allCat1_coef.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr><br>\n",
    "\n",
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation, Reshape\n",
    "# from keras.layers.recurrent import LSTM, RNN, GRU, SimpleRNN\n",
    "# from keras.models import load_model\n",
    "# import keras\n",
    "# import h5py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #default layers = 6, neurons list always should equal 6\n",
    "# def build_NN(inShape, nnType='RNN'):\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(inShape[1], 64, input_length=maxLen))  #input layer\n",
    "#     if nnType == 'RNN':\n",
    "#         model.add(SimpleRNN(32, return_sequences=True))\n",
    "#         model.add(SimpleRNN(32))\n",
    "#         model.add(Dense(16, activation='relu'))\n",
    "#         model.add(Dense(8, activation='relu'))\n",
    "#     elif nnType == 'GRU':\n",
    "#         #model.add(Dense(64, input_shape=(inShape[1])))  #input layer\n",
    "#         model.add(GRU(32, return_sequences=True))\n",
    "#         model.add(GRU(32))\n",
    "#         model.add(Dense(16, activation='relu'))\n",
    "#         model.add(Dense(8, activation='relu'))\n",
    "#     elif nnType == 'LSTM':\n",
    "#         #model.add(Dense(64, input_shape=(inShape[1])))  #input layer\n",
    "#         model.add(LSTM(32, return_sequences=True)) \n",
    "#         model.add(LSTM(32))\n",
    "#         model.add(Dense(16, activation='relu'))      \n",
    "#         model.add(Dense(8, activation='relu'))\n",
    "#     elif nnType == 'BASE':\n",
    "#         #model.add(Dense(64, input_shape=(inShape[1],)))  #input layer\n",
    "#         model.add(Dense(32, activation='relu'))\n",
    "#         model.add(Dense(32, activation='relu'))\n",
    "#         model.add(Dense(16, activation='relu'))\n",
    "#         model.add(Reshape((-1,)))\n",
    "#         model.add(Dense(8, activation='relu'))\n",
    "#     else:\n",
    "#         print('should not be here')\n",
    "    \n",
    "#     model.add(Dense(1, activation='linear', kernel_initializer=\"uniform\")) #output layer\n",
    "#     model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "#     #model.summary() \n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #params for NN\n",
    "# epochs = 10\n",
    "# batchSize = 3000\n",
    "\n",
    "# #Need to prep the data for the NN\n",
    "\n",
    "# X = tokenizer.texts_to_sequences(train5k)\n",
    "# data = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "\n",
    "# modelRNN = build_NN(tfidf_train.shape, nnType='RNN')\n",
    "# modelRNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
